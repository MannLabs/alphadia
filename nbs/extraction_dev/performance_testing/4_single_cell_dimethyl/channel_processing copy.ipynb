{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os, psutil\n",
    "\n",
    "from rocket_fft import numpy_like, scipy_like\n",
    "\n",
    "numpy_like()\n",
    "\n",
    "os.environ['NUMEXPR_MAX_THREADS'] = '20'\n",
    "os.environ['NUMBA_DEBUGINFO'] = '0'\n",
    "\n",
    "from alphadia.extraction import processlogger\n",
    "processlogger.init_logging()\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger()\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import neptune.new as neptune\n",
    "import alphatims.bruker as bruker\n",
    "\n",
    "from alphabase.spectral_library.base import SpecLibBase\n",
    "from alphadia.extraction.planning import Plan, Workflow\n",
    "\n",
    "yaml_file = 'config.yaml'\n",
    "\n",
    "raw_files = [\n",
    "    '/Users/georgwallmann/Documents/data/alphadia_benchmarking/raw_data/2023_04_27_synchroPasef_mDIA/20230422_TIMS05_PaSk_MCT_SA_HeLa_mDIA_P001_diaP_pydiAID8_1300V_S2-D1_1_1811.d',\n",
    "    '/Users/georgwallmann/Documents/data/alphadia_benchmarking/raw_data/2023_04_27_synchroPasef_mDIA/20230422_TIMS05_PaSk_MCT_SA_HeLa_mDIA_P001_diaP_pydiAID8_1300V_S2-E3_1_1819.d',\n",
    "    '/Users/georgwallmann/Documents/data/alphadia_benchmarking/raw_data/2023_04_27_synchroPasef_mDIA/20230422_TIMS05_PaSk_MCT_SA_HeLa_mDIA_P001_diaP_pydiAID8_1300V_S2-F5_1_1827.d',\n",
    "    '/Users/georgwallmann/Documents/data/alphadia_benchmarking/raw_data/2023_04_27_synchroPasef_mDIA/20230422_TIMS05_PaSk_MCT_SA_HeLa_mDIA_P001_diaP_pydiAID8_1300V_S2-H1_1_1835.d'\n",
    "]\n",
    "\n",
    "\n",
    "output_location = '/Users/georgwallmann/Documents/data/alphadia_benchmarking/alphadia_runs/2023_04_27_alphadia_mDIA_synchroPasef/data_small_lib_reprocessing'\n",
    "\n",
    "try:\n",
    "    neptune_token = os.environ['NEPTUNE_TOKEN']\n",
    "except KeyError:\n",
    "    logger.error('NEPTUNE_TOKEN environtment variable not set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_lib = SpecLibBase()\n",
    "test_lib_location = '/Users/georgwallmann/Documents/data/alphadia_benchmarking/libraries/marvin_scp/MSfragger_library_mod_noLossType_d0_d4_d8_d12_shared_eg_n_fragments_mbr.hdf'\n",
    "test_lib.load_hdf(test_lib_location, load_mod_seq=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plan = Plan(raw_files, config_update = \n",
    "            {'extraction':\n",
    "                {\n",
    "                    'target_mobility_tolerance': 0.04,\n",
    "                    'target_rt_tolerance': 60,\n",
    "                    'target_ms1_tolerance': 10,\n",
    "                    'min_epochs': 3,\n",
    "                }\n",
    "            }\n",
    "        )\n",
    "plan.from_spec_lib_base(test_lib)\n",
    "for dia_data, precursors_flat, fragments_flat in plan.get_run_data():\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    reference_flat = precursors_flat[precursors_flat['channel'] == 0].copy()\n",
    "\n",
    "    workflow = Workflow(\n",
    "        plan.config, \n",
    "        dia_data, \n",
    "        reference_flat, \n",
    "        fragments_flat\n",
    "    )\n",
    "\n",
    "    workflow.calibration()\n",
    "    d0_df = workflow.extraction()\n",
    "\n",
    "    raw_name = precursors_flat['raw_name'].iloc[0]\n",
    "    d0_df.to_csv(os.path.join(output_location, f'{raw_name}_d0.tsv'), sep = '\\t', index = False)\n",
    "\n",
    "    d0_df = d0_df[d0_df['qval'] < 0.01]\n",
    "    d0_df = d0_df[d0_df['decoy'] == 0]\n",
    "    workflow.calibration_manager.predict(precursors_flat, 'precursor')\n",
    "    workflow.calibration_manager.predict(fragments_flat, 'fragment')\n",
    "\n",
    "    from alphadia.extraction import utils, plexscoring, quadrupole\n",
    "    import alphatims.utils\n",
    "    from tqdm import tqdm\n",
    "    import numba as nb\n",
    "\n",
    "    multiplex = plexscoring.Multiplexer(precursors_flat, fragments_flat, d0_df.copy())\n",
    "    candidates_df = multiplex()\n",
    "    candidates_df['rank'] = np.zeros(len(candidates_df), dtype = np.int64)\n",
    "    candidates_df = utils.calculate_score_groups(candidates_df, group_channels=True)\n",
    "\n",
    "    score_group_container = plexscoring.ScoreGroupContainer()\n",
    "    score_group_container.build_from_df(\n",
    "        candidates_df['elution_group_idx'].values.astype(np.uint32),\n",
    "        candidates_df['score_group_idx'].values.astype(np.uint32),\n",
    "        candidates_df['precursor_idx'].values.astype(np.uint32),\n",
    "        candidates_df['channel'].values.astype(np.uint8),\n",
    "        candidates_df['flat_frag_start_idx'].values.astype(np.uint32),\n",
    "        candidates_df['flat_frag_stop_idx'].values.astype(np.uint32),\n",
    "\n",
    "        candidates_df['scan_start'].values,\n",
    "        candidates_df['scan_stop'].values,\n",
    "        candidates_df['scan_center'].values,\n",
    "        candidates_df['frame_start'].values,\n",
    "        candidates_df['frame_stop'].values,\n",
    "        candidates_df['frame_center'].values,\n",
    "\n",
    "        candidates_df['charge'].values,\n",
    "        candidates_df['mz_calibrated'].values.astype(np.float32),\n",
    "        candidates_df[utils.get_isotope_column_names(candidates_df.columns)].values.astype(np.float32),\n",
    "    )\n",
    "\n",
    "    q = quadrupole.SimpleQuadrupole(dia_data.cycle)\n",
    "    fragment_container = plexscoring.assemble_fragments(fragments_flat)\n",
    "\n",
    "    config = plexscoring.CandidateConfig()\n",
    "    config.max_cardinality = 1\n",
    "    config.score_grouped = True\n",
    "\n",
    "    alphatims.utils.set_threads(10)\n",
    "\n",
    "    plexscoring._executor(\n",
    "        range(len(score_group_container)), \n",
    "        score_group_container,\n",
    "        fragment_container,\n",
    "        dia_data,\n",
    "        config.jitclass(),\n",
    "        q.jit,\n",
    "        False\n",
    "    )\n",
    "\n",
    "    dict_list = []\n",
    "    precursor_idx_list = []\n",
    "    channel_list = []\n",
    "\n",
    "\n",
    "    for elem in tqdm(score_group_container):\n",
    "        for i, candidate in enumerate(elem.candidates):\n",
    "            if (len(candidate.features) > 0) and (candidate.channel != 0):\n",
    "                \n",
    "                precursor_idx_list.append(candidate.precursor_idx)\n",
    "                dict_list.append(candidate.features)\n",
    "                channel_list.append(candidate.channel)\n",
    "\n",
    "    df = pd.DataFrame(dict_list)\n",
    "    df['precursor_idx'] = precursor_idx_list\n",
    "    df['channel'] = channel_list\n",
    "\n",
    "    df = df.merge(\n",
    "        precursors_flat[['precursor_idx', 'decoy', 'proteins',]],\n",
    "        on='precursor_idx',\n",
    "        how='left'\n",
    "    )\n",
    "\n",
    "    features_df = df[set(df.columns) - set(['top3_reference_template_frame_cosine','top3_reference_template_scan_cosine', 'top3_y_ion_correlation','top3_b_ion_correlation'])].copy()\n",
    "    all_feature_columns = list(set(features_df.columns) - set(['channel', 'precursor_idx','decoy','proteins']))\n",
    "\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.pipeline import Pipeline\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.metrics import roc_auc_score\n",
    "    from sklearn.metrics import roc_curve\n",
    "    from sklearn.metrics import auc\n",
    "    from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "    from alphadia.library import fdr_to_q_values\n",
    "\n",
    "    output_dfs = []\n",
    "\n",
    "    for channel in [4,8]:\n",
    "        channel_df = features_df[features_df['channel'].isin([channel, 12])]\n",
    "        channel_df['decoy'] = np.zeros(len(channel_df))\n",
    "        channel_df.loc[channel_df['channel'] == 12, 'decoy'] = 1\n",
    "\n",
    "        channel_df = channel_df.dropna()\n",
    "\n",
    "        pipeline = Pipeline([\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('GBC',MLPClassifier(hidden_layer_sizes=(50, 25, 5), max_iter=1000, alpha=0.1, learning_rate='adaptive', learning_rate_init=0.001, early_stopping=True, tol=1e-6))\n",
    "        ])\n",
    "\n",
    "        X = channel_df[all_feature_columns].values\n",
    "        y = channel_df['decoy'].values\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "        print(X.shape)\n",
    "        print(y.shape)\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "        pipeline.fit(X_train, y_train)\n",
    "        \n",
    "\n",
    "        y_test_proba = pipeline.predict_proba(X_test)[:,1]\n",
    "        y_test_pred = np.round(y_test_proba)\n",
    "\n",
    "        y_train_proba = pipeline.predict_proba(X_train)[:,1]\n",
    "        y_train_pred = np.round(y_train_proba)\n",
    "\n",
    "        channel_df['proba'] = pipeline.predict_proba(X)[:,1]\n",
    "        # subset to the best candidate for every precursor\n",
    "        channel_df = channel_df.sort_values(by=['proba'], ascending=True)\n",
    "        features_best_df = channel_df\n",
    "\n",
    "\n",
    "        # ROC curve\n",
    "        fpr_test, tpr_test, _ = roc_curve(y_test, y_test_proba)\n",
    "        roc_auc_test = auc(fpr_test, tpr_test)\n",
    "\n",
    "        fpr_train, tpr_train, _ = roc_curve(y_train, y_train_proba)\n",
    "        roc_auc_train = auc(fpr_train, tpr_train)\n",
    "\n",
    "        \n",
    "        \n",
    "        # plotting\n",
    "\n",
    "        fig, axs = plt.subplots(ncols=3, figsize=(12,3.5))\n",
    "\n",
    "        axs[0].plot(fpr_test, tpr_test,label=\"ROC test (area = %0.2f)\" % roc_auc_test)\n",
    "        axs[0].plot(fpr_train, tpr_train,label=\"ROC train (area = %0.2f)\" % roc_auc_train)\n",
    "\n",
    "        axs[0].plot([0, 1], [0, 1], color=\"k\", linestyle=\"--\")\n",
    "        axs[0].set_xlim([0.0, 1.0])\n",
    "        axs[0].set_ylim([0.0, 1.05])\n",
    "        axs[0].set_xlabel(\"false positive rate\")\n",
    "        axs[0].set_ylabel(\"true positive rate\")\n",
    "        axs[0].set_title(\"ROC Curve\")\n",
    "        axs[0].legend(loc=\"lower right\")\n",
    "        \n",
    "        sns.histplot(data=features_best_df, x='proba', hue='decoy', bins=30, element=\"step\", fill=False, ax=axs[1])\n",
    "        axs[1].set_xlabel('score')\n",
    "        axs[1].set_ylabel('number of precursors')\n",
    "        axs[1].set_title(\"Score Distribution\")\n",
    "\n",
    "        features_best_df = features_best_df.sort_values(['proba'], ascending=True)\n",
    "        target_values = 1-features_best_df['decoy'].values\n",
    "        decoy_cumsum = np.cumsum(features_best_df['decoy'].values)\n",
    "        target_cumsum = np.cumsum(target_values)\n",
    "        fdr_values = decoy_cumsum/target_cumsum\n",
    "        features_best_df['qval'] = fdr_to_q_values(fdr_values)\n",
    "        q_val = features_best_df[features_best_df['qval'] <0.05 ]['qval'].values\n",
    "\n",
    "        ids = np.arange(0, len(q_val), 1)\n",
    "        axs[2].plot(q_val, ids)\n",
    "        axs[2].set_xlim(-0.001, 0.05)\n",
    "        axs[2].set_xlabel('q-value')\n",
    "        axs[2].set_ylabel('number of precursors')\n",
    "        axs[2].set_title(\"Identifications\")\n",
    "        \n",
    "        fig.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        print(len(features_best_df[features_best_df['qval'] <=0.01 ]['qval']))\n",
    "        print(features_best_df[features_best_df['qval'] <=0.01 ]['proteins'].nunique())\n",
    "\n",
    "\n",
    "        output_dfs.append(features_best_df[features_best_df['qval'] <=0.01])\n",
    "\n",
    "    del dia_data\n",
    "\n",
    "    stop_time = time.time()\n",
    "    duration = stop_time - start_time\n",
    "\n",
    "    duration_df = pd.DataFrame({'raw_name': [raw_name], 'duration': [duration]})\n",
    "    duration_df.to_csv(os.path.join(output_location, f'{raw_name}_duration.tsv'), sep = '\\t', index = False)\n",
    "\n",
    "    output_dfs = pd.concat(output_dfs)\n",
    "    output_dfs.to_csv(os.path.join(output_location, f'{raw_name}_d4_d8.tsv'), sep = '\\t', index = False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alpha",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
