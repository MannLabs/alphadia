{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0:00:00.772927 \u001b[33;20m WARNING: WARNING: Temp mmap arrays are written to /var/folders/lc/9594t94d5b5_gn0y04w1jh980000gn/T/temp_mmap_sobds5c3. Cleanup of this folder is OS dependant, and might need to be triggered manually! Current space: 568,760,164,352\u001b[0m\n",
      "0:00:00.785171 \u001b[33;20m WARNING: WARNING: No Bruker libraries are available for this operating system. Mobility and m/z values need to be estimated. While this estimation often returns acceptable results with errors < 0.02 Th, huge errors (e.g. offsets of 6 Th) have already been observed for some samples!\u001b[0m\n",
      "0:00:00.785664 \u001b[38;20m INFO: \u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os, psutil\n",
    "\n",
    "from rocket_fft import numpy_like, scipy_like\n",
    "\n",
    "numpy_like()\n",
    "\n",
    "os.environ['NUMEXPR_MAX_THREADS'] = '20'\n",
    "os.environ['NUMBA_DEBUGINFO'] = '0'\n",
    "\n",
    "from alphadia.extraction import processlogger\n",
    "processlogger.init_logging()\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger()\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import neptune.new as neptune\n",
    "import alphatims.bruker as bruker\n",
    "\n",
    "from alphabase.spectral_library.base import SpecLibBase\n",
    "from alphadia.extraction.planning import Plan, Workflow\n",
    "\n",
    "yaml_file = 'config.yaml'\n",
    "\n",
    "raw_files = [\n",
    "    '/Users/georgwallmann/Documents/data/alphadia_benchmarking/raw_data/2023_04_27_synchroPasef_mDIA/20230422_TIMS05_PaSk_MCT_SA_HeLa_mDIA_SyP_4dig_scans_S2-C1_1_1805.d',\n",
    "    '/Users/georgwallmann/Documents/data/alphadia_benchmarking/raw_data/2023_04_27_synchroPasef_mDIA/20230422_TIMS05_PaSk_MCT_SA_HeLa_mDIA_SyP_4dig_scans_S2-G1_1_1829.d',\n",
    "    '/Users/georgwallmann/Documents/data/alphadia_benchmarking/raw_data/2023_04_27_synchroPasef_mDIA/20230422_TIMS05_PaSk_MCT_SA_HeLa_mDIA_SyP_4dig_scans_S2-E5_1_1821.d',\n",
    "    '/Users/georgwallmann/Documents/data/alphadia_benchmarking/raw_data/2023_04_27_synchroPasef_mDIA/20230422_TIMS05_PaSk_MCT_SA_HeLa_mDIA_SyP_4dig_scans_S2-D3_1_1813.d',\n",
    "    '/Users/georgwallmann/Documents/data/alphadia_benchmarking/raw_data/2023_04_27_synchroPasef_mDIA/20230422_TIMS05_PaSk_MCT_SA_HeLa_mDIA_SyP_2scans_each150Da_S2-B6_1_1804.d',\n",
    "    '/Users/georgwallmann/Documents/data/alphadia_benchmarking/raw_data/2023_04_27_synchroPasef_mDIA/20230422_TIMS05_PaSk_MCT_SA_HeLa_mDIA_SyP_2scans_each150Da_S2-F6_1_1828.d',\n",
    "    '/Users/georgwallmann/Documents/data/alphadia_benchmarking/raw_data/2023_04_27_synchroPasef_mDIA/20230422_TIMS05_PaSk_MCT_SA_HeLa_mDIA_SyP_2scans_each150Da_S2-E4_1_1820.d',\n",
    "    '/Users/georgwallmann/Documents/data/alphadia_benchmarking/raw_data/2023_04_27_synchroPasef_mDIA/20230422_TIMS05_PaSk_MCT_SA_HeLa_mDIA_SyP_2scans_each150Da_S2-D2_1_1812.d',\n",
    "    '/Users/georgwallmann/Documents/data/alphadia_benchmarking/raw_data/2023_04_27_synchroPasef_mDIA/20230422_TIMS05_PaSk_MCT_SA_HeLa_mDIA_P001_diaP_pydiAID8_1300V_S2-D1_1_1811.d',\n",
    "    '/Users/georgwallmann/Documents/data/alphadia_benchmarking/raw_data/2023_04_27_synchroPasef_mDIA/20230422_TIMS05_PaSk_MCT_SA_HeLa_mDIA_P001_diaP_pydiAID8_1300V_S2-F5_1_1827.d',\n",
    "    '/Users/georgwallmann/Documents/data/alphadia_benchmarking/raw_data/2023_04_27_synchroPasef_mDIA/20230422_TIMS05_PaSk_MCT_SA_HeLa_mDIA_P001_diaP_pydiAID8_1300V_S2-E3_1_1819.d',\n",
    "    '/Users/georgwallmann/Documents/data/alphadia_benchmarking/raw_data/2023_04_27_synchroPasef_mDIA/20230422_TIMS05_PaSk_MCT_SA_HeLa_mDIA_P001_diaP_pydiAID8_1300V_S2-H1_1_1835.d'\n",
    "]\n",
    "\n",
    "\n",
    "output_location = '/Users/georgwallmann/Documents/data/alphadia_benchmarking/alphadia_runs/2023_04_27_alphadia_mDIA_synchroPasef/data_small_lib_mbr_15ppm'\n",
    "\n",
    "try:\n",
    "    neptune_token = os.environ['NEPTUNE_TOKEN']\n",
    "except KeyError:\n",
    "    logger.error('NEPTUNE_TOKEN environtment variable not set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_lib = SpecLibBase()\n",
    "test_lib_location = '/Users/georgwallmann/Documents/data/alphadia_benchmarking/libraries/marvin_scp/MSfragger_library_mod_noLossType_d0_d4_d8_d12_shared_eg_n_fragments_mbr.hdf'\n",
    "test_lib.load_hdf(test_lib_location, load_mod_seq=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0:00:04.783458 \u001b[32;20m PROGRESS:       _   _      _         ___ ___   _   \u001b[0m\n",
      "0:00:04.783974 \u001b[32;20m PROGRESS:      /_\\ | |_ __| |_  __ _|   \\_ _| /_\\  \u001b[0m\n",
      "0:00:04.784259 \u001b[32;20m PROGRESS:     / _ \\| | '_ \\ ' \\/ _` | |) | | / _ \\ \u001b[0m\n",
      "0:00:04.784517 \u001b[32;20m PROGRESS:    /_/ \\_\\_| .__/_||_\\__,_|___/___/_/ \\_\\\u001b[0m\n",
      "0:00:04.784841 \u001b[32;20m PROGRESS:            |_|                            \u001b[0m\n",
      "0:00:04.785075 \u001b[32;20m PROGRESS: \u001b[0m\n",
      "0:00:04.785445 \u001b[38;20m INFO: loading default config from /Users/georgwallmann/Documents/git/alphadia/alphadia/extraction/../../misc/config/default.yaml\u001b[0m\n",
      "0:00:04.791389 \u001b[38;20m INFO: Applying config update from dict\u001b[0m\n",
      "0:00:04.791854 \u001b[32;20m PROGRESS: version: 1.0.2\u001b[0m\n",
      "0:00:04.792121 \u001b[32;20m PROGRESS: hostname: Georgs-MacBook-Pro.local\u001b[0m\n",
      "0:00:04.792444 \u001b[32;20m PROGRESS: date: 2023-05-25 00:13:04\u001b[0m\n",
      "0:00:08.400297 \u001b[38;20m INFO: renaming precursor_columns columns\u001b[0m\n",
      "0:00:08.401317 \u001b[38;20m INFO: renaming fragment_columns columns\u001b[0m\n",
      "0:00:08.401673 \u001b[38;20m INFO: ========= Library Stats =========\u001b[0m\n",
      "0:00:08.401919 \u001b[38;20m INFO: Number of precursors: 220,333\u001b[0m\n",
      "0:00:08.432929 \u001b[38;20m INFO: \tthereof targets:176,268\u001b[0m\n",
      "0:00:08.433400 \u001b[38;20m INFO: \tthereof decoys: 44,065\u001b[0m\n",
      "0:00:08.435933 \u001b[38;20m INFO: Number of elution groups: 44,067\u001b[0m\n",
      "0:00:08.436201 \u001b[38;20m INFO: \taverage size: 5.00\u001b[0m\n",
      "0:00:08.442324 \u001b[38;20m INFO: Number of proteins: 4,997\u001b[0m\n",
      "0:00:08.443633 \u001b[38;20m INFO: Number of channels: 4 ([ 0  4  8 12])\u001b[0m\n",
      "0:00:08.444000 \u001b[38;20m INFO: Isotopes Distribution for 6 isotopes\u001b[0m\n",
      "0:00:08.444239 \u001b[38;20m INFO: =================================\u001b[0m\n",
      "0:00:08.445234 \u001b[33;20m WARNING: no precursor_idx column found, creating one\u001b[0m\n",
      "/Users/georgwallmann/Documents/git/alphabase/alphabase/peptide/precursor.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.fillna('', inplace=True)\n",
      "/Users/georgwallmann/Documents/git/alphabase/alphabase/peptide/precursor.py:42: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['nAA']= df.sequence.str.len().astype(np.int32)\n",
      "0:00:08.684711 \u001b[38;20m INFO: rt_type automatically determined as norm\u001b[0m\n",
      "0:00:08.685120 \u001b[38;20m INFO: Importing data from /Users/georgwallmann/Documents/data/alphadia_benchmarking/raw_data/2023_04_27_synchroPasef_mDIA/20230422_TIMS05_PaSk_MCT_SA_HeLa_mDIA_SyP_4dig_scans_S2-C1_1_1805.d\u001b[0m\n",
      "0:00:08.685804 \u001b[38;20m INFO: Using .d import for /Users/georgwallmann/Documents/data/alphadia_benchmarking/raw_data/2023_04_27_synchroPasef_mDIA/20230422_TIMS05_PaSk_MCT_SA_HeLa_mDIA_SyP_4dig_scans_S2-C1_1_1805.d\u001b[0m\n",
      "0:00:08.686123 \u001b[38;20m INFO: Reading frame metadata for /Users/georgwallmann/Documents/data/alphadia_benchmarking/raw_data/2023_04_27_synchroPasef_mDIA/20230422_TIMS05_PaSk_MCT_SA_HeLa_mDIA_SyP_4dig_scans_S2-C1_1_1805.d\u001b[0m\n",
      "0:00:09.197756 \u001b[38;20m INFO: Reading 16,189 frames with 2,588,634,740 detector events for /Users/georgwallmann/Documents/data/alphadia_benchmarking/raw_data/2023_04_27_synchroPasef_mDIA/20230422_TIMS05_PaSk_MCT_SA_HeLa_mDIA_SyP_4dig_scans_S2-C1_1_1805.d\u001b[0m\n",
      "100%|██████████| 16189/16189 [00:09<00:00, 1702.17it/s]\n",
      "0:00:18.799988 \u001b[38;20m INFO: Indexing /Users/georgwallmann/Documents/data/alphadia_benchmarking/raw_data/2023_04_27_synchroPasef_mDIA/20230422_TIMS05_PaSk_MCT_SA_HeLa_mDIA_SyP_4dig_scans_S2-C1_1_1805.d...\u001b[0m\n",
      "0:00:18.801141 \u001b[38;20m INFO: Bruker DLL not available, estimating mobility values\u001b[0m\n",
      "0:00:18.801451 \u001b[38;20m INFO: Bruker DLL not available, estimating mz values\u001b[0m\n",
      "0:00:18.803241 \u001b[38;20m INFO: Indexing quadrupole dimension\u001b[0m\n",
      "0:00:26.626249 \u001b[38;20m INFO: Transposing detector events\u001b[0m\n",
      "0:01:21.768786 \u001b[38;20m INFO: Finished transposing data\u001b[0m\n",
      "0:01:27.815138 \u001b[38;20m INFO: Successfully imported data from /Users/georgwallmann/Documents/data/alphadia_benchmarking/raw_data/2023_04_27_synchroPasef_mDIA/20230422_TIMS05_PaSk_MCT_SA_HeLa_mDIA_SyP_4dig_scans_S2-C1_1_1805.d\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "plan = Plan(raw_files, config_update = \n",
    "            {'extraction':\n",
    "                {\n",
    "                    'target_mobility_tolerance': 0.04,\n",
    "                    'target_rt_tolerance': 30,\n",
    "                    'target_ms1_tolerance': 15,\n",
    "                    'min_epochs': 3,\n",
    "                }\n",
    "            }\n",
    "        )\n",
    "plan.from_spec_lib_base(test_lib)\n",
    "for dia_data, precursors_flat, fragments_flat in plan.get_run_data():\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    reference_flat = precursors_flat[precursors_flat['channel'] == 0].copy()\n",
    "\n",
    "    workflow = Workflow(\n",
    "        plan.config, \n",
    "        dia_data, \n",
    "        reference_flat, \n",
    "        fragments_flat\n",
    "    )\n",
    "\n",
    "    workflow.calibration()\n",
    "    d0_df = workflow.extraction()\n",
    "\n",
    "    raw_name = precursors_flat['raw_name'].iloc[0]\n",
    "    d0_df.to_csv(os.path.join(output_location, f'{raw_name}_d0.tsv'), sep = '\\t', index = False)\n",
    "\n",
    "    d0_df = d0_df[d0_df['qval'] < 0.01]\n",
    "    d0_df = d0_df[d0_df['decoy'] == 0]\n",
    "    workflow.calibration_manager.predict(precursors_flat, 'precursor')\n",
    "    workflow.calibration_manager.predict(fragments_flat, 'fragment')\n",
    "\n",
    "    from alphadia.extraction import utils, plexscoring, quadrupole\n",
    "    import alphatims.utils\n",
    "    from tqdm import tqdm\n",
    "    import numba as nb\n",
    "\n",
    "    multiplex = plexscoring.Multiplexer(precursors_flat, fragments_flat, d0_df.copy())\n",
    "    candidates_df = multiplex()\n",
    "    candidates_df['rank'] = np.zeros(len(candidates_df), dtype = np.int64)\n",
    "    candidates_df = utils.calculate_score_groups(candidates_df, group_channels=True)\n",
    "\n",
    "    score_group_container = plexscoring.ScoreGroupContainer()\n",
    "    score_group_container.build_from_df(\n",
    "        candidates_df['elution_group_idx'].values.astype(np.uint32),\n",
    "        candidates_df['score_group_idx'].values.astype(np.uint32),\n",
    "        candidates_df['precursor_idx'].values.astype(np.uint32),\n",
    "        candidates_df['channel'].values.astype(np.uint8),\n",
    "        candidates_df['flat_frag_start_idx'].values.astype(np.uint32),\n",
    "        candidates_df['flat_frag_stop_idx'].values.astype(np.uint32),\n",
    "\n",
    "        candidates_df['scan_start'].values,\n",
    "        candidates_df['scan_stop'].values,\n",
    "        candidates_df['scan_center'].values,\n",
    "        candidates_df['frame_start'].values,\n",
    "        candidates_df['frame_stop'].values,\n",
    "        candidates_df['frame_center'].values,\n",
    "\n",
    "        candidates_df['charge'].values,\n",
    "        candidates_df['mz_calibrated'].values.astype(np.float32),\n",
    "        candidates_df[utils.get_isotope_column_names(candidates_df.columns)].values.astype(np.float32),\n",
    "    )\n",
    "\n",
    "    q = quadrupole.SimpleQuadrupole(dia_data.cycle)\n",
    "    fragment_container = plexscoring.assemble_fragments(fragments_flat)\n",
    "\n",
    "    config = plexscoring.CandidateConfig()\n",
    "    config.max_cardinality = 1\n",
    "    config.score_grouped = True\n",
    "\n",
    "    alphatims.utils.set_threads(10)\n",
    "\n",
    "    plexscoring._executor(\n",
    "        range(len(score_group_container)), \n",
    "        score_group_container,\n",
    "        fragment_container,\n",
    "        dia_data,\n",
    "        config.jitclass(),\n",
    "        q.jit,\n",
    "        False\n",
    "    )\n",
    "\n",
    "    dict_list = []\n",
    "    precursor_idx_list = []\n",
    "    channel_list = []\n",
    "\n",
    "\n",
    "    for elem in tqdm(score_group_container):\n",
    "        for i, candidate in enumerate(elem.candidates):\n",
    "            if (len(candidate.features) > 0) and (candidate.channel != 0):\n",
    "                \n",
    "                precursor_idx_list.append(candidate.precursor_idx)\n",
    "                dict_list.append(candidate.features)\n",
    "                channel_list.append(candidate.channel)\n",
    "\n",
    "    df = pd.DataFrame(dict_list)\n",
    "    df['precursor_idx'] = precursor_idx_list\n",
    "    df['channel'] = channel_list\n",
    "\n",
    "    df = df.merge(\n",
    "        precursors_flat[['precursor_idx', 'decoy', 'proteins',]],\n",
    "        on='precursor_idx',\n",
    "        how='left'\n",
    "    )\n",
    "\n",
    "    features_df = df[set(df.columns) - set(['top3_reference_template_frame_cosine','top3_reference_template_scan_cosine', 'top3_y_ion_correlation','top3_b_ion_correlation'])].copy()\n",
    "    all_feature_columns = list(set(features_df.columns) - set(['channel', 'precursor_idx','decoy','proteins']))\n",
    "\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.pipeline import Pipeline\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.metrics import roc_auc_score\n",
    "    from sklearn.metrics import roc_curve\n",
    "    from sklearn.metrics import auc\n",
    "    from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "    from alphadia.library import fdr_to_q_values\n",
    "\n",
    "    output_dfs = []\n",
    "\n",
    "    for channel in [4,8]:\n",
    "        channel_df = features_df[features_df['channel'].isin([channel, 12])]\n",
    "        channel_df['decoy'] = np.zeros(len(channel_df))\n",
    "        channel_df.loc[channel_df['channel'] == 12, 'decoy'] = 1\n",
    "\n",
    "        channel_df = channel_df.dropna()\n",
    "\n",
    "        pipeline = Pipeline([\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('GBC',MLPClassifier(hidden_layer_sizes=(50, 25, 5), max_iter=1000, alpha=0.1, learning_rate='adaptive', learning_rate_init=0.001, early_stopping=True, tol=1e-6))\n",
    "        ])\n",
    "\n",
    "        X = channel_df[all_feature_columns].values\n",
    "        y = channel_df['decoy'].values\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "        print(X.shape)\n",
    "        print(y.shape)\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "        pipeline.fit(X_train, y_train)\n",
    "        \n",
    "\n",
    "        y_test_proba = pipeline.predict_proba(X_test)[:,1]\n",
    "        y_test_pred = np.round(y_test_proba)\n",
    "\n",
    "        y_train_proba = pipeline.predict_proba(X_train)[:,1]\n",
    "        y_train_pred = np.round(y_train_proba)\n",
    "\n",
    "        channel_df['proba'] = pipeline.predict_proba(X)[:,1]\n",
    "        # subset to the best candidate for every precursor\n",
    "        channel_df = channel_df.sort_values(by=['proba'], ascending=True)\n",
    "        features_best_df = channel_df\n",
    "\n",
    "\n",
    "        # ROC curve\n",
    "        fpr_test, tpr_test, _ = roc_curve(y_test, y_test_proba)\n",
    "        roc_auc_test = auc(fpr_test, tpr_test)\n",
    "\n",
    "        fpr_train, tpr_train, _ = roc_curve(y_train, y_train_proba)\n",
    "        roc_auc_train = auc(fpr_train, tpr_train)\n",
    "\n",
    "        \n",
    "        \n",
    "        # plotting\n",
    "\n",
    "        fig, axs = plt.subplots(ncols=3, figsize=(12,3.5))\n",
    "\n",
    "        axs[0].plot(fpr_test, tpr_test,label=\"ROC test (area = %0.2f)\" % roc_auc_test)\n",
    "        axs[0].plot(fpr_train, tpr_train,label=\"ROC train (area = %0.2f)\" % roc_auc_train)\n",
    "\n",
    "        axs[0].plot([0, 1], [0, 1], color=\"k\", linestyle=\"--\")\n",
    "        axs[0].set_xlim([0.0, 1.0])\n",
    "        axs[0].set_ylim([0.0, 1.05])\n",
    "        axs[0].set_xlabel(\"false positive rate\")\n",
    "        axs[0].set_ylabel(\"true positive rate\")\n",
    "        axs[0].set_title(\"ROC Curve\")\n",
    "        axs[0].legend(loc=\"lower right\")\n",
    "        \n",
    "        sns.histplot(data=features_best_df, x='proba', hue='decoy', bins=30, element=\"step\", fill=False, ax=axs[1])\n",
    "        axs[1].set_xlabel('score')\n",
    "        axs[1].set_ylabel('number of precursors')\n",
    "        axs[1].set_title(\"Score Distribution\")\n",
    "\n",
    "        features_best_df = features_best_df.sort_values(['proba'], ascending=True)\n",
    "        target_values = 1-features_best_df['decoy'].values\n",
    "        decoy_cumsum = np.cumsum(features_best_df['decoy'].values)\n",
    "        target_cumsum = np.cumsum(target_values)\n",
    "        fdr_values = decoy_cumsum/target_cumsum\n",
    "        features_best_df['qval'] = fdr_to_q_values(fdr_values)\n",
    "        q_val = features_best_df[features_best_df['qval'] <0.05 ]['qval'].values\n",
    "\n",
    "        ids = np.arange(0, len(q_val), 1)\n",
    "        axs[2].plot(q_val, ids)\n",
    "        axs[2].set_xlim(-0.001, 0.05)\n",
    "        axs[2].set_xlabel('q-value')\n",
    "        axs[2].set_ylabel('number of precursors')\n",
    "        axs[2].set_title(\"Identifications\")\n",
    "        \n",
    "        fig.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        print(len(features_best_df[features_best_df['qval'] <=0.01 ]['qval']))\n",
    "        print(features_best_df[features_best_df['qval'] <=0.01 ]['proteins'].nunique())\n",
    "\n",
    "\n",
    "        output_dfs.append(features_best_df[features_best_df['qval'] <=0.01])\n",
    "\n",
    "    del dia_data\n",
    "\n",
    "    stop_time = time.time()\n",
    "    duration = stop_time - start_time\n",
    "\n",
    "    duration_df = pd.DataFrame({'raw_name': [raw_name], 'duration': [duration]})\n",
    "    duration_df.to_csv(os.path.join(output_location, f'{raw_name}_duration.tsv'), sep = '\\t', index = False)\n",
    "\n",
    "    output_dfs = pd.concat(output_dfs)\n",
    "    output_dfs.to_csv(os.path.join(output_location, f'{raw_name}_d4_d8.tsv'), sep = '\\t', index = False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alpha",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
