{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from alphabase.spectral_library.base import SpecLibBase\n",
    "from alphadia.transferlearning.train import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 1000,\n",
       " 'max_lr': 0.0005,\n",
       " 'train_ratio': 0.8,\n",
       " 'test_interval': 1,\n",
       " 'lr_patience': 3,\n",
       " 'minimum_psms': 1200,\n",
       " 'epochs': 51,\n",
       " 'warmup_epochs': 5,\n",
       " 'nce': 25,\n",
       " 'instrument': 'Lumos'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.set_num_threads(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transfer_lib = SpecLibBase()\n",
    "transfer_lib.load_hdf('/Users/georgwallmann/Documents/data/alphadia_manuscript/2024_04_25_Dimethyl_GPF/transfer_learning_asms/speclib.transfer.hdf', load_mod_seq=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "transfer_lib.precursor_df = transfer_lib.precursor_df[~transfer_lib.precursor_df['mods'].str.contains('Dimethyl@C')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Util function to plot the metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_stats (stats_df: pd.DataFrame, loss_name: str, property: str, pre_train_dataset:str = 'all'):\n",
    "    \"\"\"\n",
    "    Plot the the metrics of the fine-tuning process.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    stats_df : pd.DataFrame\n",
    "        The dataframe containing the metrics of the fine-tuning process.\n",
    "    loss_name : str\n",
    "        The name of the loss function used eg. 'l1_loss'.\n",
    "    property : str\n",
    "        The property being predicted eg. 'rt'.\n",
    "    pre_train_dataset : str\n",
    "        The name of the dataset used to test the model before fine-tuning. for example for rt, charge we use 'all', for ms2 we use 'validation'.\n",
    "    \"\"\"\n",
    "    # converts stats to a dataframe \n",
    "    df = pd.DataFrame(stats_df)\n",
    "\n",
    "    # Pivot the DataFrame\n",
    "\n",
    "    pivot_df = df.pivot_table(index='epoch', columns=['dataset', 'property', 'metric_name'], values='value')\n",
    "    num_plots = len(pivot_df['validation'][property].columns) - 1 + len(pivot_df['train'][property].columns) - 1\n",
    "    fig_col = 2\n",
    "    fig_row = np.ceil(num_plots / fig_col).astype(int) + 1\n",
    "    fig, ax = plt.subplots(fig_row, fig_col, figsize=(15, 5 * fig_row))\n",
    "\n",
    "    x_axis = pivot_df.index.values\n",
    "    # Train and test loss\n",
    "    ax[0, 0].plot(x_axis, pivot_df['train'][property][loss_name], label=\"Train\")\n",
    "    ax[0, 0].plot(x_axis, pivot_df['validation'][property][loss_name], label=\"Validation\")\n",
    "    ax[0, 0].scatter(-1, pivot_df[pre_train_dataset][property][loss_name].values[0], label=\"Before fine-tuning\", color=\"red\")\n",
    "    ax[0, 0].set_title(\"Loss\")\n",
    "    ax[0, 0].set_xlabel(\"Epoch\")\n",
    "    ax[0, 0].set_ylabel(\"Loss\")\n",
    "    ax[0, 0].legend()\n",
    "\n",
    "    # Plot the learning rate\n",
    "    ax[0, 1].plot(x_axis, pivot_df['train'][property][\"lr\"])\n",
    "    ax[0, 1].set_title(\"Learning rate\")\n",
    "    ax[0, 1].set_xlabel(\"Epoch\")\n",
    "    ax[0, 1].set_ylabel(\"Learning rate\")\n",
    "\n",
    "\n",
    "    # Rest of the columns\n",
    "    columns_to_plot = pivot_df['validation'][property].columns.drop(loss_name)\n",
    "\n",
    "    for i, column_name in enumerate(columns_to_plot):\n",
    "        row = (i + 2) // fig_col\n",
    "        col = (i + 2) % fig_col\n",
    "        ax[row, col].plot(x_axis, pivot_df['validation'][property][column_name])\n",
    "        ax[row, col].set_title(column_name + \" (Validation)\")\n",
    "        ax[row, col].set_xlabel(\"Epoch\")\n",
    "        ax[row, col].set_ylabel(column_name)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RT Fine-tuning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tune_mgr = FinetuneManager(\n",
    "    device=\"gpu\",\n",
    "    settings=settings)\n",
    "tune_mgr.nce = 25\n",
    "tune_mgr.instrument = 'Lumos'\n",
    "transfer_lib.precursor_df = tune_mgr.predict_rt(transfer_lib.precursor_df)\n",
    "plt.scatter(transfer_lib.precursor_df['rt_norm'], transfer_lib.precursor_df['rt_norm_pred'], s=1, alpha=0.1)\n",
    "plt.xlabel('RT observed')\n",
    "plt.ylabel('RT predicted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rt_stats = tune_mgr.finetune_rt(transfer_lib.precursor_df)\n",
    "\n",
    "transfer_lib.precursor_df = tune_mgr.predict_rt(transfer_lib.precursor_df)\n",
    "\n",
    "plt.scatter(transfer_lib.precursor_df['rt_norm'], transfer_lib.precursor_df['rt_norm_pred'], s=0.1, alpha=0.1)\n",
    "plt.xlabel('RT observed')\n",
    "plt.ylabel('RT predicted')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_stats(rt_stats, 'l1_loss', 'rt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Charge Fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Testing the charge finetuning on the transfer library\n",
    "charge_stats = tune_mgr.finetune_charge(psm_df=transfer_lib.precursor_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_stats(charge_stats, 'ce_loss', 'charge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MS2 Fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the following line to only finetune the ms2 on high quality spectra\n",
    "# transfer_lib.precursor_df = transfer_lib.precursor_df[transfer_lib.precursor_df['use_for_ms2']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_similarity(precursor_df_a, precursor_df_b, intensity_df_a, intensity_df_b):\n",
    "\n",
    "    _a_df = precursor_df_a[['precursor_idx', 'frag_start_idx', 'frag_stop_idx']].copy()\n",
    "    _b_df = precursor_df_b[['precursor_idx', 'frag_start_idx', 'frag_stop_idx']].copy()\n",
    "\n",
    "    _merged_df = pd.merge(_a_df, _b_df, on='precursor_idx', suffixes=('_a', '_b'))\n",
    "    # keep only first precursor\n",
    "    _merged_df = _merged_df.drop_duplicates(subset='precursor_idx', keep='first')\n",
    "    similarity_list = []\n",
    "\n",
    "    for i, (start_a, stop_a, start_b, stop_b) in enumerate(zip(_merged_df['frag_start_idx_a'], _merged_df['frag_stop_idx_a'], _merged_df['frag_start_idx_b'], _merged_df['frag_stop_idx_b'])):\n",
    "        observed_intensity = intensity_df_a.iloc[start_a:stop_a, :4].values.flatten()\n",
    "        predicted_intensity = intensity_df_b.iloc[start_b:stop_b, :4].values.flatten()\n",
    "\n",
    "        similarity = np.dot(observed_intensity, predicted_intensity) / (np.linalg.norm(observed_intensity) * np.linalg.norm(predicted_intensity))\n",
    "        similarity_list.append({'similarity': similarity, 'index': i, 'precursor_idx': _merged_df.iloc[i]['precursor_idx']})\n",
    "\n",
    "    return pd.DataFrame(similarity_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = tune_mgr.predict_all(transfer_lib.precursor_df.copy(), predict_items=['ms2'])\n",
    "\n",
    "precursor_after_df = res['precursor_df']\n",
    "fragment_mz_after_df = res['fragment_mz_df']\n",
    "fragment_intensity_after_df = res['fragment_intensity_df']\n",
    "similarity_after_df = calculate_similarity(precursor_after_df, transfer_lib.precursor_df, fragment_intensity_after_df, transfer_lib.fragment_intensity_df)\n",
    "print(similarity_after_df['similarity'].median())\n",
    "plt.scatter(similarity_after_df['index'], similarity_after_df['similarity'], s=0.1)\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Similarity')\n",
    "plt.title('Similarity between observed and predicted MS2 spectra before fine-tuning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Testing the ms2 finetuning on the transfer library\n",
    "ms2_stats = tune_mgr.finetune_ms2(psm_df=transfer_lib.precursor_df.copy(), matched_intensity_df=transfer_lib.fragment_intensity_df.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = tune_mgr.predict_all(transfer_lib.precursor_df.copy(), predict_items=[\"ms2\"])\n",
    "\n",
    "precursor_after_df = res[\"precursor_df\"]\n",
    "fragment_mz_after_df = res[\"fragment_mz_df\"]\n",
    "fragment_intensity_after_df = res[\"fragment_intensity_df\"]\n",
    "similarity_after_df = calculate_similarity(\n",
    "    precursor_after_df,\n",
    "    transfer_lib.precursor_df,\n",
    "    fragment_intensity_after_df,\n",
    "    transfer_lib.fragment_intensity_df,\n",
    ")\n",
    "print(similarity_after_df[\"similarity\"].median())\n",
    "plt.scatter(similarity_after_df[\"index\"], similarity_after_df[\"similarity\"], s=0.1)\n",
    "plt.xlabel(\"Index\")\n",
    "plt.ylabel(\"Similarity\")\n",
    "plt.title(\"Similarity between observed and predicted MS2 spectra after fine-tuning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_stats(ms2_stats, 'l1_loss', 'ms2', pre_train_dataset='validation')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alpha",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
